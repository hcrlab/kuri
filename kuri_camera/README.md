# kuri_camera

This package provides multiple nodes for working with Kuri's camera, depending on your needs. Refer here for more information about madmux: https://github.com/KuriRobot/Kuri-Documentation/blob/master/reference/ros-packages/madmux.md

## Dependencies

- OpenCV
- libav: `apt-get install libav-tools` (you can also maybe install it by installing FFMPEG or through https://libav.org/)

## Nodes

### Python

- `ros_publisher.py` is the simplest to use and slowest node in this package. It registers a callback from madmux's MJPEG stream, converts the images into CompressedImage rosmsgs, and then publishes them.

### C++

- NOTE: For the C++ code to compile, we have to manually link to libmadmux and multiple other libraries. This requires finding the paths to these libraries. The CMake file contains the paths to those libraries on our computers -- use those as pointers to find those libraries on your computers, and change the paths accordingly.
- `ros_publisher` is the second-simplest and second-slowest node to use. This does the same thing as `ros_publisher.py`, except in C++.
- The fastest way to receive images is to use H264 compression (which compresses the image in space and time). Our approach involves porting the Unix Domain Socket (UDS) data stream directly to a TCP socket, and then reading from that TCP socket on a remote computer and processing the images.
  - `uds_to_TCP` is the node that reads bytes from the UDS socket and ports them over to a TCP socket. This must be run *on the Kuri*.
  - `tcp_test_client` is just a test client you can run to ensure that data is getting streamed to the TCP socket as expected. It will partition the stream into H264 frames and print the size and beginning bytes of each frame.
  - `h264_decoder_node` subscribes to the TCP socket, decodes the H264 stream, and displays it. This should be run *on a remote computer*. (NOTE: if you would like to use the H264 stream but process images on-board the Kuri, we recommend you change `h264_decoder.cpp` to read directly from the UDS socket, instead of the TCP socket that is generated by `uds_to_TCP`).
- NOTE: you must specify the tcpSocketHostname and the tcpSocketPort. This can be done via rosparams.

### Miscellaneous
- `display_compressed_images` will read a CompressedImage rosmsg, display it, and print out the delay between when the message was received and the timestamp on the message.

## TODO
- We have gotten the latency extremely low (~60ms not including render time) when we had H264Decoder call a callback function in H264DecoderNode which then converted it to a cv::Mat and showed it. However, that setup had two problems: 1) even though the delay was small, it would grow over the course of the node's operation since the conversion to cv::Mat was in the same thread as the decoding to AVFrame; and 2) when we added a rosmsg publish, it became even slower due to the time necessary to convert the cv::Mat to a rosmsg. To address these issues, we changed it to a setup where the H264DecoderNode could call a function in the H264Decoder to get the latest image as a cv::Mat. This now works, but there are two drawbacks that have yet to be tackled: 1) the video stream is sometimes discontinuous since the Kuri is publishing frames at a faster rate than the remote computer receives them; and 2) the latency has increased again (including rendering) to a few seconds. Therefore, todos include: 1) investigate the non-rendering latency of the current setup; 2) look into lowering the kuri bitrate to prevent a discontinuous video; and 3)see if there are optimizations that can speed up the code (possibly concurrency related optimizations). In general, for all changes, measure not only the latency after running the code, but also after the code has been running for a while (and for both, measure the rendering latency as well as the latency just to receive messages).
