# kuri_camera

This package provides multiple nodes for working with Kuri's camera, depending on your needs. Refer here for more information about madmux: https://github.com/KuriRobot/Kuri-Documentation/blob/master/reference/ros-packages/madmux.md

## Dependencies

- OpenCV
- libav: `apt-get install libav-tools` (you can also maybe install it by installing FFMPEG or through https://libav.org/)

## Nodes

### Python

- `ros_publisher.py` is the simplest to use and slowest node in this package. It registers a callback from madmux's MJPEG stream, converts the images into CompressedImage rosmsgs, and then publishes them.

### C++

- NOTE: For the C++ code to compile, you have to manually link to libmadmux and multiple other libraries. This requires finding the paths to these libraries. The CMake file contains the paths to those libraries on our computers -- use those as pointers to find those libraries on your computers, and change the paths accordingly.
- `ros_publisher` is the second-simplest and second-slowest node to use. This does the same thing as `ros_publisher.py`, except in C++.
- The fastest way to receive images is to use H264 compression (which compresses the image in space and time). Our approach involves porting the Unix Domain Socket (UDS) data stream directly to a TCP socket, and then reading from that TCP socket on a remote computer and processing the images.
  - `uds_to_TCP` is the node that reads bytes from the UDS socket and ports them over to a TCP socket. This must be run *on the Kuri*.
  - `tcp_test_client` is just a test client you can run to ensure that data is getting streamed to the TCP socket as expected. It will partition the stream into H264 frames and print the size and beginning bytes of each frame.
  - `h264_decoder_node` subscribes to the TCP socket, decodes the H264 stream, and displays it. This should be run *on a remote computer*. (NOTE: if you would like to use the H264 stream but process images on-board the Kuri, we recommend you change `h264_decoder.cpp` to read directly from the UDS socket, instead of the TCP socket that is generated by `uds_to_TCP`).
- NOTE: you must specify the tcpSocketHostname and the tcpSocketPort. This can be done via rosparams.

### Miscellaneous
- `display_compressed_images` will read a CompressedImage rosmsg, display it, and print out the delay between when the message was received and the timestamp on the message.

## TODO
- We have gotten the latency extremely low (~60ms not including rendering time) using uds_to_TCP and the h264_decoder_node. Including rendering, the delay is around 0.5 seconds. We might be able to make it marginally faster by, instead of converting the AVFrame to a cv::Mat on-demand, running another thread in the background to do that conversion. So the H264 node just gets the pre-processed cv::Mat when it needs, as opposed to adding latency to convert the Mat after the node is ready.
